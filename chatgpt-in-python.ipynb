{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#one time work \n!pip install -q pyChatGPT","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-11T13:56:38.235501Z","iopub.execute_input":"2022-12-11T13:56:38.235996Z","iopub.status.idle":"2022-12-11T13:56:55.280997Z","shell.execute_reply.started":"2022-12-11T13:56:38.235950Z","shell.execute_reply":"2022-12-11T13:56:55.279531Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from pyChatGPT import ChatGPT\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T13:57:24.452144Z","iopub.execute_input":"2022-12-11T13:57:24.452642Z","iopub.status.idle":"2022-12-11T13:57:24.462534Z","shell.execute_reply.started":"2022-12-11T13:57:24.452605Z","shell.execute_reply":"2022-12-11T13:57:24.461264Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# You need to get session token to run this code. \n\nHow to get session token?\n* Go to https://chat.openai.com/chat \n*  Create your id in it or if you already have then login.\n* After login you will see a dashboard. \n    1. On the dashboard right click and go to inspect mode. \n    2. Now go to Application \n    3. Now go to Cookies.In cookies you will find chat.openai.com cookies. \n    4. after clicking on it you will see __Secure-next-auth.session-token \n    5. In the next column there will be value and that value is your session token. \n","metadata":{}},{"cell_type":"code","source":"\nsession_token ='ENTER YOUR ON SESSION ID. GET YOUR OWN SESSION ID BY FOLLOWING ABOVE STEP.'","metadata":{"execution":{"iopub.status.busy":"2022-12-11T13:57:25.957007Z","iopub.execute_input":"2022-12-11T13:57:25.957497Z","iopub.status.idle":"2022-12-11T13:57:25.964743Z","shell.execute_reply.started":"2022-12-11T13:57:25.957454Z","shell.execute_reply":"2022-12-11T13:57:25.963273Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"api = ChatGPT(session_token)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T13:57:26.940563Z","iopub.execute_input":"2022-12-11T13:57:26.941072Z","iopub.status.idle":"2022-12-11T13:57:27.536475Z","shell.execute_reply.started":"2022-12-11T13:57:26.941029Z","shell.execute_reply":"2022-12-11T13:57:27.535188Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"response = api.send_message('Explain self-attentio from detail.')","metadata":{"execution":{"iopub.status.busy":"2022-12-11T14:14:46.350579Z","iopub.execute_input":"2022-12-11T14:14:46.351097Z","iopub.status.idle":"2022-12-11T14:16:18.869936Z","shell.execute_reply.started":"2022-12-11T14:14:46.351056Z","shell.execute_reply":"2022-12-11T14:16:18.868804Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"response","metadata":{"execution":{"iopub.status.busy":"2022-12-11T14:16:18.871681Z","iopub.execute_input":"2022-12-11T14:16:18.872434Z","iopub.status.idle":"2022-12-11T14:16:18.881259Z","shell.execute_reply.started":"2022-12-11T14:16:18.872392Z","shell.execute_reply":"2022-12-11T14:16:18.879843Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'message': \"Self-attention is a mechanism used in some types of neural networks to allow the network to focus on certain parts of the input when processing it. It is often used in natural language processing tasks, where understanding the relationships between words and sentences is important.\\n\\n\\nIn a self-attention mechanism, each element of the input is first represented as a vector, which encodes its meaning. These vectors are then processed by the network to compute a weighted sum, which represents the importance of each element in the input with respect to the other elements. This weighted sum is then used by the network to generate the output.\\n\\n\\nThe key advantage of self-attention is that it allows the network to process the input in parallel, which makes it much faster than other types of neural networks. It also allows for greater flexibility in the design of the network, since the self-attention mechanism can be stacked and configured in different ways to suit the specific needs of the task at hand.\\n\\n\\nTo understand self-attention in more detail, let's consider a simple example where the input is a sentence with five words, and the goal is to generate the output sequence. The first step is to convert each word in the input sentence into a vector, which encodes its meaning. These vectors are then processed by the self-attention mechanism to compute a weighted sum for each word in the input sentence. The weights represent the importance of each word with respect to the others, and are computed using a dot product operation between the vectors.\\n\\n\\nOnce the weights have been computed, they are used to generate the output sequence. This is done by taking the weighted sum of the vectors for each word in the input sentence, using the weights as the coefficients in the sum. This weighted sum is then passed through a non-linear activation function, which produces the final output sequence.\\n\\n\\nOverall, self-attention is a powerful tool for natural language processing, and has been used in many state-of-the-art systems in this field. It allows the network to focus on certain parts of the input when processing it, which makes it very effective for tasks such as machine translation and text summarization.\",\n 'conversation_id': '6c8c6266-a088-4a47-812e-8c8f5c142493',\n 'parent_id': 'c871d5ae-432f-436f-a709-f149a05fc130'}"},"metadata":{}}]}]}